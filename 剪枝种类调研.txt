决策树擅长处理小数据集,又好解释,所以没啥数据的小公司,尤其是医疗大数据公司非常爱用.
曾经面试时被问到剪枝的问题,所以这里总结下:
-------------------------------------------------------
关于决策树剪枝问题,分为两大类:
一、预剪枝
二、后剪枝

其中后剪枝比预剪枝更加常用,因为预剪枝不好判断树枝何时停止生长,容易欠拟合.
-------------------------------------------------------
从学术和工程角度讨论下ID3需要掌握到什么程度.
学术角度:
ID3处理连续型数据+ID3的先剪枝、REP后剪枝(离散数据)
从学习角度,掌握到这个程度即可.
工程角度:
有没有必要掌握ID3的"连续、离散型、缺失型混合数据输入决策树+
决策树剪枝"?
也就是说输入数据中,同时具有"连续型、离散型、缺失型"3种数据,并且建树完成以后再进行各种类型的后剪枝呢?

答案是没必要,原因如下:
一、数据处理、机器学习、数据挖掘领域通常都是处理完缺失值以后再输入模型,因此工程上,没必要让决策树代码内部去处理缺失值.
二、能同时处理"连续型、离散型、缺失型"3种数据+"REP后剪枝处理"的ID3算法没有现成的,网上只有"离散型+REP剪枝"的ID3代码,想要完美的ID3决策树,需要自己整合代码,消耗大量精力,且不说REP后剪枝会过度剪枝.
三、C4.5、Cart树具有更好的处理连续数值的能力,并且有更加优异的现成的剪枝算法,适合在工程中使用,因此折腾ID3算法与各种剪枝算法的整合,划不来,既没有论文支持(虽然剪枝原理用到各种决策树上都差不多),又没有现成的代码,为此消耗精力自己去实现,非常划不来.
四、李航<统计学习方法>对决策树剪枝一笔带过,周志华<机器学习>的决策树ID3剪枝部分也仅仅是针对"离散型"数据进行剪枝.
可见,对于同时处理"连续型、离散型、缺失型"3种数据的决策树进行剪枝,使用ID3意义不大.


总结:
即便是纯学术研究,把同时处理"连续型、离散型、缺失型"3种数据的ID3代码+"REP后剪枝处理"代码进行整合的意义甚微,完全没必要.
同时,ID3适合作为教学、自学使用,不适合作为工程实践使用.
工程上需要时,优先选用C4.5,cart树及其相关剪枝即可.
----------------------------------------------------


后剪枝包括以下几种:

-------------------ID3剪枝------------------------------
reduced-error pruning,需要单独的验证数据集,REP剪枝的一句是验证集说了算√

---------------C4.5剪枝--------------------------
Error Based Pruning(EBP)-C4.5
Pessimistic Error Pruning(PEP，悲观剪枝）,
PEP剪枝算法是在C4.5决策树算法中提出的,不需要单独的验证数据集

---------------Cart剪枝--------------------------
CCP(cost-complexity pruning)(Cart树-分类-剪枝)
1984 L.Breiman and J.Freidman proposed error complexity pruning (ECP) algorithm



----------------以下剪枝不予处理----------------------------
CBP(cost-based pruning)(Google上面没看到有这个说法,百度有人在提)
Minimum Error Pruning(MEP). (Niblett & Bratko, 1986).
算法的论文名称是<Learning decision rules in noisy domains>,下载不到,还是放弃吧


